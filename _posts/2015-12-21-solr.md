---
layout: post
title: "Solr"
date: 2015-12-21 15:35:30
description: "Solr"
categories:
- solr
permalink: solr
---

Solr是一个基于Lucene的Java搜索引擎服务器。Solr提供了层面搜索、命中醒目显示并且支持多种输出格式（包括 XML/XSLT 和 JSON 格式）。它易于安装和配置，而且附带了一个基于 HTTP 的管理界面。Solr已经在众多大型的网站中使用，较为成熟和稳定。Solr包装并扩展了Lucene，所以Solr的基本上沿用了Lucene的相关术语。更重要的是，Solr创建的索引与Lucene 搜索引擎库完全兼容。通过对Solr进行适当的配置，某些情况下可能需要进行编码，Solr可以阅读和使用构建到其他Lucene应用程序中的索引。此外，很多Lucene 工（如Nutch、 Luke也可以使用Solr创建的索引。  

Solr默认是不支持中文分词的，这样就需要我们手工配置中文分词器，在这里我们选用IK Analyzer中文分词器。  

IK Analyzer下载地址：https://code.google.com/p/ik-analyzer/downloads/list  

[IK Analyzer_2012_FF_hf1.zip](/downloads/solr/K Analyzer 2012FF_hf1.zip)

```vim
1：解压下载的IK Analyzer_2012_FF_hf1.zip，把IKAnalyzer2012FF_u1.jar拷贝到solr-4.10.4/example/solr-webapp/webapp/WEB-INF/lib目录下

2：在solr-4.10.4/example/solr-webapp/webapp/WEB-INF目录下创建目录classes，然后把IKAnalyzer.cfg.xml和stopword.dic拷贝到新创建的classes目录下即可。

3：修改solr core的schema文件，默认是solr-4.10.4/example/solr/collection1/conf/schema.xml,添加如下配置

<fieldType name="text_ik" class="solr.TextField">
<!--索引时候的分词器-->
<analyzer type="index" isMaxWordLength="false" class="org.wltea.analyzer.lucene.IKAnalyzer"/>
<!--查询时候的分词器-->
<analyzer type="query" isMaxWordLength="true" class="org.wltea.analyzer.lucene.IKAnalyzer"/>
</fieldType>

4：启动solr，bin/solr start

5：进入solr web界面http://localhost:port/solr

到现在为止，solr就和IK Analyzer中文分词器整合成功了。

但是，如果想自定义词库，让IK分词器可以识别。

操作步骤：

1：修改solr-4.10.4/example/solr-webapp/webapp/WEB-INF/classes目录下的IKAnalyzer.cfg.xml配置文件，添加如下配置

<entry key="ext_dict">ext.dic;</entry>

2：新建ext.dic文件，在里面添加如下内容(注意：ext.dic的编码必须是Encode in UTF-8 without BOM,否则自定义的词库不会被识别)

3：重启solr
```
配置好solr后，可以通过web管理界面进行管理和查询。web界面基本列出了大多数查询参数，可以通过这个学习lucene的查询语法。

solr的查询解析是通过queryParser来配置的（solrconfig.xml），一般我们用默认的即可。其各参数含义与用法简单解释如下

```vim
q：查询输入，必须。可以使用运算符

fq：过滤查询。可以使用运算符

sort：排序的字段，格式为field score，多个字段之间用逗号隔开，比如sum(x_f, y_f) desc, price asc，默认是score desc

start：从哪一行开始

rows：获取多少行

fl：查询要输出的字段，字段之间用逗号隔开，比如title,price,seller，星号代表所有，默认就是星号。

df:定义查询时默认的查询field。

wt：返回的数据类型，可以是JSON、XML、python、ruby、php、csv等格式。

indent：true/false，返回的XML格式是否需要缩进(格式化展示)，默认为false

debugQuery：调试查询，会输出查询过程的一些参数。

高亮相关：

高亮是通过searchComponent来配置的，在solrconfig.xml中配置名为highlight的searchComponent即可，默认的实现是solr.HighlightComponent。

hl：true/false,是否高亮显示

hl.fl：高亮显示的字段

hl.example.pre：高亮显示的前缀

hl.exapmle.post：高亮显示的后缀

hl.requireFieldMatch：是否只在查询指定的field（只有当hl.usePhraseHighlighter为true时才生效）高亮显示，默认是在所有field都高亮

hl.usePhraseHighlighter：true/false,使用SpanScorer高亮查询短语

hl.highlightMultiTerm：true/false,如果SpanScorer被启用，这个参数针对前缀/模糊/范围/通配符等开启高亮显示

facet：true/false

facet是solr的高级搜索功能之一，可以给用户提供更友好的搜索体验（类似于面包屑导航的功能）。在搜索关键字的同时,能够按照 facet指定的字段进行分组统计。比如商品的分类、商品的规格等。facet的字段必须被索引，无须分词（分词意义不大），也无须存储。详细可参考《Solr的facet查询》

facet的查询结果返回字段为facet_counts，与responseHeader、response同级。

facet.query：类似于filter的语法，对任意字段进行筛选

facet.field：需要进行facet的字段

facet.prefix：对facet字段的前缀过滤

facet.sort：true/false，对facet以哪种顺序返回，true为按照count值从大到小排序，默认为true

spellcheck：拼写检查

spellcheck是通过component的方式实现的，你可以在solrconfig.xml文件中配置searchComponent来完成拼写检查的功能，默认的实现是solr.SpellCheckComponent，具体的配置参数和实现原理可以看这里《spellCheckComponent》

spatial：空间搜索

spatial是专门针对空间数据进行搜索的，空间位置的索引和存储fieldType是LatLonType或者SpatialRecursivePrefixTreeFieldType，通过使用空间搜索，你可以对点、面等数据建立索引，以圆形、方形或其他形状进行范围搜索，以及对搜索结果按距离排序等等，具体的配置参数和实现原理可以看这里《SpatialSearch》
 
检索运算符：

冒号":"： field:value结构查询，表示字段field值为value的查询。

通配符：？(任意一个字符) *(任意字符)

布尔操作：AND(并且，同&&) OR(或者，同||) +(包含) -(不包含) NOT(同!)，注意AND、OR、NOT均为大写

范围：[A TO B](从A到B之间，包含A和B,注意TO大写)，{A TO B}（从A到B之间，不包含A和B,注意TO大写）

子运算：(...)优先运算

模糊检索：~表示模糊检索，比如：roam~将找到形如foam和roams的单词；roam~0.8，检索返回相似度在0.8以上的记录

控制相关度：^表示相关度，如检索jakarta apache，同时希望让”jakarta”的相关度更加好，那么在其后加上”^”符号和增量值，即jakarta^4 apache
```
